For each model, we provide COMET and spBLEU scores for each language pair in flores101. Additionally, 
we include the average scores across 101 languages for the corresponding central language (summary_101.csv). 
To compare with the m2m100 model, which supports only 85 languages, 
we also provide the average scores across those 85 languages (summary_85.csv).
For the results of each language pair for M2M-100 and Lego-MT, please refer to the [Lego-MT](https://github.com/CONE-MT/Lego-MT).